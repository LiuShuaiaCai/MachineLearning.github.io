
  <!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>激活函数 | 机器学习笔记</title>
  <meta name="author" content="LiuShuaiaCai">
  
  <meta name="description" content="Deep Learning">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="激活函数"/>
  <meta property="og:site_name" content="机器学习笔记"/>

  
    <meta property="og:image" content=""/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="机器学习笔记" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>

  <body>
    <a name="top"></a>
  	<header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">机器学习笔记</a></h1>
  <h2><a href="/">Deep Learning</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about-me">About</a></li>
    
      <li><a href="/atom.xml">Rss</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  	<div id="content" class="inner">
  	<div id="main-col" class="alignleft"><div id="wrapper"><article class="post hidden_show">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2018-08-30T06:06:08.000Z"><a href="/2018/08/30/激活函数/">2018-08-30</a></time>
      
      
  
    <h1 class="title">激活函数</h1>
  

    </header>
    <div class="entry">
      
        <h2 id="1、激活函数-Activation-Function"><a href="#1、激活函数-Activation-Function" class="headerlink" title="1、激活函数(Activation Function)"></a>1、激活函数(Activation Function)</h2><p>算法设计</p>
<h4 id="1-1、什么是激活函数"><a href="#1-1、什么是激活函数" class="headerlink" title="1.1、什么是激活函数"></a>1.1、什么是激活函数</h4><p>如下图，在神经元中，输入的 inputs 通过加权，求和后，还被作用了一个函数，这个函数就是激活函数 Activation Function。<br><img src="/images/active.png" alt="activate"></p>
<h4 id="1-2、激活函数的特点"><a href="#1-2、激活函数的特点" class="headerlink" title="1.2、激活函数的特点"></a>1.2、激活函数的特点</h4><p>非线性： 当激活函数是线性的时候，一个两层的神经网络就可以逼近基本上所有的函数了。<br>可微： 当优化方法是基于梯度的时候，这个性质是必须的。<br>单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数。<br>_ ： 当激活函数满足这个性质的时候，如果参数的初始化是random的很小的值，那么神经网络的训练将会很高效。<br>输出值范围： 当激活函数输出值是 有限 的时候，基于梯度的优化方法会更加 稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是 无限 的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的学习率。</p>
<h4 id="1-3、为什么要用激活函数"><a href="#1-3、为什么要用激活函数" class="headerlink" title="1.3、为什么要用激活函数"></a>1.3、为什么要用激活函数</h4><p>如果不用激励函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的线性组合。<br>如果使用的话，激活函数给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中。</p>
<h2 id="2、sigmoid-函数"><a href="#2、sigmoid-函数" class="headerlink" title="2、sigmoid 函数"></a>2、sigmoid 函数</h2><p>公式：<script type="math/tex">\sigma(x) = \frac{1}{1 + e^{-x}}</script></p>
<p><img src="/images/sigmoid.png" alt="sigmoid"><br><a id="more"></a><br>在sigmod函数中我们可以看到，其输出是在(0,1)这个开区间内，这点很有意思，可以联想到概率，但是严格意义上讲，不要当成概率。sigmod函数曾经是比较流行的，它可以想象成一个神经元的放电率，在中间斜率比较大的地方是神经元的敏感区，在两边斜率很平缓的地方是神经元的抑制区。</p>
<p>当然，流行也是曾经流行，这说明函数本身是有一定的缺陷的。</p>
<p>1) 当输入稍微远离了坐标原点，函数的梯度就变得很小了，几乎为零。在神经网络反向传播的过程中，我们都是通过微分的链式法则来计算各个权重w的微分的。当反向传播经过了sigmod函数，这个链条上的微分就很小很小了，况且还可能经过很多个sigmod函数，最后会导致权重w对损失函数几乎没影响，这样不利于权重的优化，这个问题叫做梯度饱和，也可以叫梯度弥散。</p>
<p>2) 函数输出不是以0为中心的，这样会使权重更新效率降低。对于这个缺陷，在斯坦福的课程里面有详细的解释。</p>
<p>3) sigmod函数要进行指数运算，这个对于计算机来说是比较慢的。<br>python代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># sigmoid函数公式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    y = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="comment"># sigmoid 显示</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_sigmoid</span><span class="params">()</span>:</span></span><br><span class="line">    x = np.arange(<span class="number">-8</span>, <span class="number">8</span>, <span class="number">0.2</span>)</span><br><span class="line">    y = sigmoid(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置坐标原点</span></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    <span class="comment"># 隐藏上、右边</span></span><br><span class="line">    ax.spines[<span class="string">'right'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">    ax.spines[<span class="string">'top'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">    <span class="comment"># 设置左下边为轴</span></span><br><span class="line">    ax.xaxis.set_ticks_position(<span class="string">'bottom'</span>)</span><br><span class="line">    ax.spines[<span class="string">'bottom'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>))</span><br><span class="line">    ax.yaxis.set_ticks_position(<span class="string">'left'</span>)</span><br><span class="line">    ax.spines[<span class="string">'left'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>))</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    <span class="comment"># 设置边距</span></span><br><span class="line">    ax.set_xticks(np.arange(<span class="number">-5</span>, <span class="number">5.1</span>, <span class="number">2</span>))</span><br><span class="line">    ax.set_yticks(np.arange(<span class="number">-0.5</span>, <span class="number">1.1</span>, <span class="number">0.5</span>))</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">plot_sigmoid()</span><br></pre></td></tr></table></figure></p>
<h2 id="3、tanh函数"><a href="#3、tanh函数" class="headerlink" title="3、tanh函数"></a>3、tanh函数</h2><p>公式：<script type="math/tex">\tanh(x) = \frac {\sinh(x)}{\cosh(x)} = \frac {e^x - e^{-x}}{e^x + e^{-x}}</script><br><img src="/images/tanh.png" alt="tanh"><br>tanh是双曲正切函数，tanh函数和sigmod函数的曲线是比较相近的，咱们来比较一下看看。首先相同的是，这两个函数在输入很大或是很小的时候，输出都几乎平滑，梯度很小，不利于权重更新；不同的是输出区间，tanh的输出区间是在(-1,1)之间，而且整个函数是以0为中心的，这个特点比sigmod的好。</p>
<p>一般二分类问题中，隐藏层用tanh函数，输出层用sigmod函数。不过这些也都不是一成不变的，具体使用什么激活函数，还是要根据具体的问题来具体分析，还是要靠调试的。</p>
<p>python 代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tanh函数公式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanh</span><span class="params">(x=<span class="number">0</span>, bool=False)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> bool==<span class="keyword">False</span>:</span><br><span class="line">        y = (np.exp(x) - <span class="number">1</span>/np.exp(x)) / (np.exp(x) + <span class="number">1</span>/np.exp(x))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y = np.tanh((<span class="number">0</span>, np.pi*<span class="number">1j</span>, np.pi*<span class="number">1j</span>/<span class="number">2</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"> </span><br><span class="line"><span class="comment"># tanh函数显示</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_tanh</span><span class="params">()</span>:</span></span><br><span class="line">    x = np.arange(<span class="number">-8</span>, <span class="number">8</span>, <span class="number">0.2</span>)</span><br><span class="line">    y = tanh(x)</span><br><span class="line">    <span class="comment"># 设置坐标原点</span></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    <span class="comment"># 隐藏上、右边</span></span><br><span class="line">    ax.spines[<span class="string">'right'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">    ax.spines[<span class="string">'top'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">    <span class="comment"># 设置左下边为轴</span></span><br><span class="line">    ax.xaxis.set_ticks_position(<span class="string">'bottom'</span>)</span><br><span class="line">    ax.spines[<span class="string">'bottom'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>))</span><br><span class="line">    ax.yaxis.set_ticks_position(<span class="string">'left'</span>)</span><br><span class="line">    ax.spines[<span class="string">'left'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>))</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    <span class="comment"># 设置边距</span></span><br><span class="line">    ax.set_xticks(np.arange(<span class="number">-5</span>, <span class="number">5.1</span>, <span class="number">1</span>))</span><br><span class="line">    ax.set_yticks(np.arange(<span class="number">-1.0</span>, <span class="number">1.1</span>, <span class="number">0.5</span>))</span><br><span class="line">plot_tanh()</span><br></pre></td></tr></table></figure></p>
<h2 id="4、ReLU-函数"><a href="#4、ReLU-函数" class="headerlink" title="4、ReLU 函数"></a>4、ReLU 函数</h2><p>公式：<script type="math/tex">f(x) = max(0,x)</script><br><img src="/images/relu.png" alt="relu"><br>ReLU(Rectified Linear Unit)函数是目前比较火的一个激活函数，相比于sigmod函数和tanh函数，它有以下几个优点：</p>
<p>1) 在输入为正数的时候，不存在梯度饱和问题。</p>
<p>2) 计算速度要快很多。ReLU函数只有线性关系，不管是前向传播还是反向传播，都比sigmod和tanh要快很多。（sigmod和tanh要计算指数，计算速度会比较慢）</p>
<p>当然，缺点也是有的：</p>
<p>1) 当输入是负数的时候，ReLU是完全不被激活的，这就表明一旦输入到了负数，ReLU就会死掉。这样在前向传播过程中，还不算什么问题，有的区域是敏感的，有的是不敏感的。但是到了反向传播过程中，输入负数，梯度就会完全到0，这个和sigmod函数、tanh函数有一样的问题。</p>
<p>2) 我们发现ReLU函数的输出要么是0，要么是正数，这也就是说，ReLU函数也不是以0为中心的函数。</p>
<p>python 代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ReLU函数公式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x &lt; <span class="number">0</span>:</span><br><span class="line">        y = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y = x</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="comment"># ReLU函数显示</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_relu</span><span class="params">()</span>:</span></span><br><span class="line">    x = np.arange(<span class="number">-10</span>,<span class="number">10</span>,<span class="number">0.1</span>)</span><br><span class="line">    y = list(map(relu,x))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置坐标原点</span></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    <span class="comment"># 隐藏上、右边</span></span><br><span class="line">    ax.spines[<span class="string">'right'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">    ax.spines[<span class="string">'top'</span>].set_color(<span class="string">'none'</span>)</span><br><span class="line">    <span class="comment"># 设置左下边为轴</span></span><br><span class="line">    ax.xaxis.set_ticks_position(<span class="string">'bottom'</span>)</span><br><span class="line">    ax.spines[<span class="string">'bottom'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>))</span><br><span class="line">    ax.yaxis.set_ticks_position(<span class="string">'left'</span>)</span><br><span class="line">    ax.spines[<span class="string">'left'</span>].set_position((<span class="string">'data'</span>, <span class="number">0</span>))</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line"></span><br><span class="line">plot_relu()</span><br></pre></td></tr></table></figure></p>

      
    </div>


    <footer>
      
        

        
        <div class="bdsharebuttonbox">
    <a href="#" class="bds_more" data-cmd="more"></a>
    <a href="#" class="bds_qzone" data-cmd="qzone"></a>
    <a href="#" class="bds_tsina" data-cmd="tsina"></a>
    <a href="#" class="bds_tqq" data-cmd="tqq"></a>
    <a href="#" class="bds_renren" data-cmd="renren"></a>
    <a href="#" class="bds_weixin" data-cmd="weixin"></a>
</div>

<script>
    window._bd_share_config = {
        "common": {
            "bdSnsKey": {},
            "bdText": "",
            "bdMini": "2",
            "bdPic": "",
            "bdStyle": "0",
            "bdSize": "16"
        },
        "share": {},
        "image": {
            "viewList": ["qzone", "tsina", "tqq", "renren", "weixin"],
            "viewText": "分享到",
            "viewSize": "16"
        },
        "selectShare": {
            "bdContainerClass": null,
            "bdSelectMiniList": ["qzone", "tsina", "tqq", "renren", "weixin"]
        }
    };
    with(document) 0[(getElementsByTagName('head')[0] || body).appendChild(createElement('script')).src = 'http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion=' + ~(-new Date() / 36e5)];
</script>
      
      <div class="clearfix"></div>
    </footer>
  </div>
  <!-- 
    <section id="comment">
        <h1 class="title">留言</h1>
        <div class="ds-thread" data-thread-key="2018/08/30/激活函数/"></div>
    </section>
 -->
</article>

  <aside id="sidebar" class="alignright">
         <!--02-->
        <div id="toc" class="toc-article">
    <div class="toc-title">目录</div>
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、激活函数-Activation-Function"><span class="toc-text">1、激活函数(Activation Function)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1、什么是激活函数"><span class="toc-text">1.1、什么是激活函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2、激活函数的特点"><span class="toc-text">1.2、激活函数的特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3、为什么要用激活函数"><span class="toc-text">1.3、为什么要用激活函数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、sigmoid-函数"><span class="toc-text">2、sigmoid 函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3、tanh函数"><span class="toc-text">3、tanh函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4、ReLU-函数"><span class="toc-text">4、ReLU 函数</span></a></li></ol>
</div>
      
  </aside>

<!-- <script src="/js/jquery-3.2.1.min.js"></script>
<script src="/js/syntax.js"></script> -->


</div></div>
      <div class="clearfix"></div>
  	</div>
    <div id = 'r_top'>
	<ul>
		<li class='top'><a href='#top'></a></li>
		<li class='close' data='0'><a href='javascript:;'></a></li>
		<li class='bottom'><a href='#bottom'></a></li>
	</ul>
</div>

    <footer id="footer" class="inner"><a name='bottom'></a>
<div class="alignleft">
  
  &copy; 2018 LiuShuaiaCai
  
</div>
<div class="clearfix"></div>
</footer>
    <script src="http://lib.sinaapp.com/js/jquery/2.0.3/jquery-2.0.3.min.js"></script>
<script type="text/javascript">
//<![CDATA[
if (typeof jQuery == 'undefined') {
  document.write(unescape("%3Cscript src='/js/jquery-2.0.3.min.js' type='text/javascript'%3E%3C/script%3E"));
}
// ]]>
</script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<script type="text/javascript">
var duoshuo_shortname = 'feifan';
var duoshuoQuery = {short_name:duoshuo_shortname};
    (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'https://unpkg.com/embed-js@5.0.3/umd/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
</script>

<script src="/js/toc.js"></script>
<script src="/js/top.js"></script>
<script src="/js/syntax.js"></script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
  </html>

